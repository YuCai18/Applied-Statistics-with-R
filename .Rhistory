1+1
load("D:/ChromeCoreDownloads/R-Decision-Tree-Examples-master/.RData")
View(dsList)
View(shuttle)
install.packages("ggplot2")
x <- c(5,8,7,7,10,8,4,6,6,3,5,6,6,4,4,5,4,3,7,4,6,6,3,5,9,3,5,7,7,6)
group <- c(rep("1",6),rep("2",6),rep("3",6),rep("4",6),rep("5",6))
dat = data.frame(x = x,group=group)
dat
attach(dat) #
table(group) #每个group计数
fit = aov(x~group,data = dat)
summary(fit)#生成方差分析表 F的比值=MSA/MSE=9.117/2.34=3.896
dat
attach(dat) #
table(group) #每个group计数
fit = aov(x~group,data = dat)
summary(fit)#生成方差分析表 F的比值=MSA/MSE=9.117/2.34=3.896
#by group
aggregate(x,by=list(group),mean)#求组内平均值
aggregate(x,by=list(group),sd)#求组内标准差
mean(x)
sum(x^2)
n = length(x)
k = 5 #组数
#求F的边界值，F是能解释的和不能解释的比值
qf(1-0.05,k-1,n-k) #2.75871 而3.896 > 2.758,则拒绝原假设，药物有差别
#方差分析的前提是独立性、正态性和方差齐性
#测试方差齐性
library(car)
leveneTest(x~as.factor(group),data = dat) #然后看p值
#多重比较:Tukey方法
library(gplots)
plotmeans(x~group,xlab = "type",ylab = "days")
#双因素方差分析 two way anova 考虑交互作用
#为了比较3种松树在4个不同的地区的生长情况有无差别，在每个地区对每种松树随机地选取5株，测量它们的胸径，得到的数据列表如下:
y <- c(23, 15, 26, 13, 21,
25, 20, 21, 16, 18,
21, 17, 16,  24, 27,
14, 17, 19, 20, 24,
28, 22, 25, 19, 26,
30, 26, 26, 20, 28,
19, 24, 19, 25, 29,
17, 21, 18, 26, 23,
18, 10, 12, 22, 13,
15, 21, 22, 14, 12,
23, 25, 19, 13, 22,
18, 12, 23, 22, 19)
##松树
A <- c(rep("A1",20),rep("A2",20),rep("A3",20))
##地区
B <- rep(c(rep("B1",5),rep("B2",5),rep("B3",5),rep("B4",5)),3)
dat <- data.frame(y=y,A=A,B=B)
dat
attach(dat)
fit = aov(y~A*B,data=dat) #交互作用不显著，则需要剔除交互作用回到上面的写法y~A+B
summary(fit)
table(A,B)
#计算拒绝域
alpha = 0.05
qf(1-alpha,2,48) #3.190727 计算F值
#剔除交互作用回到上面的写法y~A+B
fit1 = aov(y~A+B,data=dat) #0.000311是代表因素A显著，0.4790代表因素B不显著。
summary(fit1)
qf(1-alpha,2,54) #3.168246
#分组计算
aggregate(y,by=list(A,B),mean)
aggregate(y,by=list(A,B),sd)
#检验方差齐性
bartlett.test(y~A,data=dat)
bartlett.test(y~B,data=dat)
par(mfrow=c(1,2)) #一行两列
)
)
interaction.plot(B, A, y, type="b", col=c("red", "blue"), pch = c(16, 18), main="Interaction between B and A")
par(mfrow=c(1,2)) #一行两列
interaction.plot(A, B, y, type="b", col = c("red", "blue"), pch = c(16, 18), main="Interaction between A and B")
interaction.plot(B, A, y, type="b", col=c("red", "blue"), pch = c(16, 18), main="Interaction between B and A")
#横坐标代表三种因素A1，A2，A3，不同颜色代表因素B
#横坐标代表三种因素A1，A2，A3，不同颜色代表因素B
#左边那个图很明显没有交互作用，不管哪条线都是一个中间高两边低的情况。如果有条线是直接上去的，那就说明在因素A不同的情况下，对于y均值的趋势发生了变化，这时候表明我们可能需要考虑A和B的交互作用。
#右边那个图比左边那个图稍微有点不一样，说明了在改变因素B的时候，因素A出现了比较显著的变换。通过假设检验证明，得到因素A是显著而因素B不显著。
#绘图
library(HH)
interaction2wt(y~A*B)
interaction2wt(y~A*B)
x <- c(60,62,64,65,66,67,68,70,72,74)
y <- c(63.6,65.2,66,65.5,66.9,67.1,67.4,68.3,70.1,70)
dat <- data.frame(x=x,y=y)
plot(dat)
fit = lm(y~x)
summary(fit)
coefficients(fit) #获取参数
anova(fit) #得到回归分析表
#求拒绝域
n = length(x)
alpha = 0.05
qt(1-alpha/2,n-2)
confint(fit,parm="x",level=0.95) #置信度是95 %,计算置信区间
#绘制回归的拟合线
plot(dat)
abline(fit)
#导入新数据集
rm(list=ls())
setwd("D:/R/RWorkPlace/应用数理统计")
dat <- read.csv("eg-1.csv",header=T)
attach(dat)
fit <- lm(y~x)
summary(fit)
#预测（计算x0=5的时候，E(y0)的区间估计和y0的预测区间）
newdata = data.frame(x=5)
View(newdata)
predict(fit,newdata,interval = "confidence") #估计区间
predict(fit,newdata,interval = "predict") #预测区间
#绘图
newdata1 <- data.frame(x=seq(0,52,1))
conf <- predict(fit, newdata1, interval="confidence")  #估计区间
pre <- predict(fit, newdata1, interval="predict") #预测区间
xx <- seq(0,52,1)
plot(dat)
lines(xx,conf[,1])
lines(xx,conf[,2],lty=2)
lines(xx,conf[,3],lty=2)
lines(xx,pre[,2],lty=3,col=2)
lines(xx,pre[,3],lty=3,col=2)
legend(35,5,c("confidence","prediction"),lty=c(2,3),col=c(1,2))
#老师给的代码(层次聚类)
Consumer = read.csv("consumer2018.csv", header = TRUE, fileEncoding = "GBK")
Cosumer  = Consumer[, -c(2, 3)]
Cosumer
Cosumer  = Consumer[, -c(2, 3)]
Cosumer
View(Cosumer)
View(Cosumer)
View(Cosumer)
data.mat = as.matrix(Cosumer[, 2:9]); rownames(data.mat)=Cosumer[, 1]
View(data.mat)
View(data.mat)
View(Cosumer)
#### 编写函数计算总离差平方和、类内离差平方和和R^2统计量
#总平方和（Total Sum of Squares, TSS）
tss.cal = function(x) sum(scale(x, scale = F)^2)
#类内的平方和（Within-Cluster Sum of Squares, WSS）
wss.cal = function(x, clst) sum(by(x, INDICES=clst,FUN = tss.cal))
#计算R平方（R^2）。R平方是衡量聚类效果的指标。
rsq.cal = function(x, clst) (tss.cal(x)-wss.cal(x, clst))/tss.cal(x)
rsq = vector("numeric", 14)
res = hclust(dist(scale(data.mat)), method = "ward.D")
res
for(ii in 2:15){
clst = cutree(res, ii)
rsq[ii-1] = rsq.cal(data.mat, clst)
}
plot(2:15, rsq,  type="b", xlab="K", ylab=expression(R^2), col = "blue", lwd = 3)
m = c("single","complete","median","average","centroid","ward.D")
h = list()
reh = list()
opar = par(mfrow=c(3, 2))
for (i in 1:length(m)){
h[[i]]=hclust(dist(scale(data.mat)), method = m[i])
plot(h[[i]], main = paste("Method: ", m[i]), hang = -1)
reh[[i]] = rect.hclust(h[[i]], k = 5)
}
#我自己的模板
#层次聚类法
rm(list=ls()) #删除环境中的数字,清空缓存
setwd("D:/R/RWorkPlace/应用数理统计")
DM=read.csv("DRfull.csv")
head(DM)
hc = hclust(dist(scale(DM[,-1])),method="ward.D2")
plot(hc,labels = DM[,1],cex=.4,main=("Method:ward.D2"),xlab="")
plot(hc,labels = DM[,1],cex=.4,main=("Method:ward.D2"),xlab="")
Id = identify(hc) #手动点击图片选择类别,然后按esc退出
for(i in 1:length(Id)){
print(DM[Id[[i]],1])
}
#Kmeans聚类
rm(list=ls()) #删除环境中的数字,清空缓存
setwd("D:/R/RWorkPlace/应用数理统计")
w = read.csv("kmeansFig.csv", header = TRUE)
attach(w)
w
#choose k
library(NbClust)
choose_k =NbClust(scale(w1),distance="euclidean",min.nc=2,max.nc=8,method="complete",index="all")
choose_k =NbClust(scale(w),distance="euclidean",min.nc=2,max.nc=8,method="complete",index="all")
a = kmeans(w,4)
a
plot(w,pch = a$cluster)
plot(w,pch = a$cluster)
text(a$center,expression(c[1],c[2],c[3]),col=2)
text(a$center,expression(c[1],c[2],c[3],c[4]),col=2)
plot(w,pch = a$cluster)
text(a$center,expression(c[1],c[2],c[3],c[4]),col=2)
DM=read.csv("DRfull.csv")
DM
#现有埃及卡拉马村庄每月记录儿童身高的数据，做一元线性回归。
rm(list=ls())
datas<-data.frame(age=18:29,height=c(76.1,77,78.1,78.2,78.8,79.7,79.9,81.1,81.2,81.8,82.8,83.5))
datas
fit <- lm(height~age,data=datas)
summary(fit) #截距和斜率的值都是显著的，且R^2也比较大
plot(datas)
abline(fit)
#绘制回归诊断图
par(mfrow = c(2,2))
plot(fit)
attach(datas)
y.res = fit$residuals
y.fit = predict(fit)
par(mfrow = c(2,1))
plot(age,y.res)
abline(h = 0,lty = 3)
plot(y.fit,y.res)
abline(h = 0,lty = 3)
#检验是否符合正态分布
shapiro.test(y.res)
#检验残差是否独立，用p值检验是否要拒绝原假设
#若误差项不独立，那么回归模型的许多处理，包括误差项估计、假设检验等都将没有推导依据。
#由于残差是误差的合理估计，因此检验统计量通常是建立在残差的基础上。检验误差独立性的最常用方法，是对残差的一阶自相关性进行Durbin-Watson检验。
#DW接近于0，表示残差中存在正自相关:如果DW接近于4，表示残差中存在负自相关:如果DW接近于2，表示残差独立性。
library(car)
durbinWatsonTest(fit) #DW=2.40776
hat.plot <- function(fit) {
p <- length(coefficients(fit))
n <- length(fitted(fit))
plot(hatvalues(fit), main="Index Plot of Hat Values")
abline(h=c(2,3)*p/n, col="red", lty=2)
identify(1:n, hatvalues(fit), names(hatvalues(fit)))
}
hat.plot(fit)
hat.plot <- function(fit) {
p <- length(coefficients(fit))
n <- length(fitted(fit))
plot(hatvalues(fit), main="Index Plot of Hat Values")
abline(h=c(2,3)*p/n, col="red", lty=2)
identify(1:n, hatvalues(fit), names(hatvalues(fit)))
}
hat.plot(fit)
hatvalues(fit) #leverage
dffits(fit)
cooks.distance(fit)
covratio(fit)
influence.measures(fit)
cutoff = 4/(nrow(datas)-2) #4/(n-p-1) n是样本量大小
cutoff
plot(fit,which = 4,cook.levels = cutoff)
abline(h = cutoff,Ity=2,col="red") #绘制强影响点
hat.plot <- function(fit) {
p <- length(coefficients(fit))
n <- length(fitted(fit))
plot(hatvalues(fit), main="Index Plot of Hat Values")
abline(h=c(2,3)*p/n, col="red", lty=2)
identify(1:n, hatvalues(fit), names(hatvalues(fit)))
}
hat.plot(fit)
hatvalues(fit) #leverage
dffits(fit)
cooks.distance(fit)
covratio(fit)
influence.measures(fit)
cutoff = 4/(nrow(datas)-2) #4/(n-p-1) n是样本量大小
cutoff
plot(fit,which = 4,cook.levels = cutoff)
abline(h = cutoff,Ity=2,col="red") #绘制强影响点
library(car)
influencePlot(fit,id.method="identify",main="")
#蔡煜
#24-12-09
#主成分分析
setwd("D:/R/RWorkPlace/应用数理统计")
library(ggplot2)
library(factoextra)
student=read.table("student.txt",header=TRUE)
#第一种写法（一般用于行数大于列数的情况）
#princomp提供的是载荷矩阵（loadings），这更多用于解释每个主成分的方差贡献
student.pca = princomp(student, cor = TRUE) #如果数据变量具有不同的量纲或数量级，选择cor = TRUE进行标准化
#第二种写法（两种情况都可以用）
#prcomp提供的是旋转矩阵（rotation），可以用来理解主成分与原始变量之间的关系
#student.pca = prcomp(student,center=F,scale. = T)
#student.pca
summary(student.pca, loadings = TRUE)
student.pca$scores
#绘制折线图
par(mfrow = c(1, 2))
screeplot(student.pca, type = "lines", main = "Scree Plot", lwd = 2)
#加上蓝色的横直线
abline(h = 0.5598064^2, lty = 2, col = "blue", lwd = 3)
biplot(student.pca)
#第二种写法（两种情况都可以用）
#prcomp提供的是旋转矩阵（rotation），可以用来理解主成分与原始变量之间的关系
#student.pca = prcomp(student,center=F,scale. = T)
#student.pca
summary(student.pca, loadings = TRUE)
fviz_pca_ind(student.pca,
col.ind = "cos2",
gradient.cols =c("red", "blue", "black"),
repel = TRUE)
biplot(student.pca)
#第二种写法（两种情况都可以用）
#prcomp提供的是旋转矩阵（rotation），可以用来理解主成分与原始变量之间的关系
#student.pca = prcomp(student,center=F,scale. = T)
#student.pca
summary(student.pca, loadings = TRUE)
student
#蔡煜
#24-12-09
#主成分分析
setwd("D:/R/RWorkPlace/应用数理统计")
library(ggplot2)
library(factoextra)
student=read.table("student.txt",header=TRUE)
#第一种写法（一般用于行数大于列数的情况）
#princomp提供的是载荷矩阵（loadings），这更多用于解释每个主成分的方差贡献
student.pca = princomp(student, cor = TRUE) #如果数据变量具有不同的量纲或数量级，选择cor = TRUE进行标准化
#第二种写法（两种情况都可以用）
#prcomp提供的是旋转矩阵（rotation），可以用来理解主成分与原始变量之间的关系
#student.pca = prcomp(student,center=F,scale. = T)
#student.pca
summary(student.pca, loadings = TRUE)
student.pca$scores
princomp.rank(PCA,m=2,plot=T)  #主成分排名与作图
library(factoextra)
princomp.rank(PCA,m=2,plot=T)  #主成分排名与作图
princomp.rank(student.pca,m=2,plot=T)  #主成分排名与作图
princomp.rank(student.pca,m=2,plot=T)  #主成分排名与作图
princomp.rank<-function(PCA,m=2,plot=F)
princomp.rank(student.pca,m=2,plot=T)  #主成分排名与作图
library(mvstats)
install.packages("mvstats")
library(mvstats)
princomp.rank(student.pca,m=2,plot=T)  #主成分排名与作图
library(mvstats)
install.packages("mvstats")
student.pca$scores
s = student.pca$scores
plot(student.pca,type="lines")
abline(h=1,lty=2)
M = cor(student)
M
library(corrplot)
corrplot(M)
score_fa = factanal(score,factors = 2,rotation = "varimax") #选择方差最大的方式
score_fa = factanal(student,factors = 2,rotation = "varimax") #选择方差最大的方式
score_fa = factanal(student,factors = 1,rotation = "varimax") #选择方差最大的方式
score_fa
#输出载荷矩阵
score_fa$loadings
#输出因子方差
score_fa$Vars
View(M)
View(s)
View(s)
plot(s[,1],s[,2])
#真题
data <- data.frame(
A = c(1, 1, 1, 1, 2, 2, 2, 2),
B = c(1, 1, 2, 2, 1, 1, 2, 2),
C = c(1, 2, 1, 2, 1, 2, 1, 2),
D = c(1, 2, 2, 1, 2, 1, 1, 2),
ExperimentData = c(1.02, 0.78, 1.06, 0.94, 1.12, 1.16, 0.85, 0.97)
)
# 计算每个因子在不同水平下的平均响应值
means <- aggregate(ExperimentData ~ A + B + C + D, data, mean)
means
colnames(range_data)[ncol(range_data)] <- "Range"
# 计算极差
range_data <- aggregate(ExperimentData ~ A + B + C + D, data, range)
colnames(range_data)[ncol(range_data)] <- "Range"
# 将极差数据合并回均值数据
analysis <- merge(means, range_data, by = c("A", "B", "C", "D"))
analysis$Range_A <- analysis$ExperimentData.y[analysis$A == 1] - analysis$ExperimentData.y[analysis$A == 2]
analysis$Range_A <- analysis$ExperimentData.y[analysis$A == 1] - analysis$ExperimentData.y[analysis$A == 2]
#真题
#极差分析的核心是计算每个因子在不同水平下的响应变量的平均值，然后求取这些平均值的极差。
data <- data.frame(
A = c(1, 1, 1, 1, 2, 2, 2, 2),
B = c(1, 1, 2, 2, 1, 1, 2, 2),
C = c(1, 2, 1, 2, 1, 2, 1, 2),
D = c(1, 2, 2, 1, 2, 1, 1, 2),
ExperimentData = c(1.02, 0.78, 1.06, 0.94, 1.12, 1.16, 0.85, 0.97)
)
library(dplyr)
# 定义一个函数来计算极差
calculate_range <- function(data, factor, response) {
# 计算每个因子水平下的响应变量平均值
means <- data %>%
group_by(!!sym(factor)) %>%
summarize(mean_response = mean(!!sym(response)))
# 计算极差
range_value <- max(means$mean_response) - min(means$mean_response)
return(range_value)
}
#真题
#极差分析的核心是计算每个因子在不同水平下的响应变量的平均值，然后求取这些平均值的极差。
data <- data.frame(
A = c(1, 1, 1, 1, 2, 2, 2, 2),
B = c(1, 1, 2, 2, 1, 1, 2, 2),
AXB = c(1, 1, 2, 2, 1, 1, 2, 2),  # A × B
C = c(1, 2, 1, 2, 1, 2, 1, 2),
AXC = c(1, 2, 1, 2, 1, 2, 1, 2),  # A × C
D = c(1, 2, 2, 1, 2, 1, 1, 2),
ExperimentData = c(1.02, 0.78, 1.06, 0.94, 1.12, 1.16, 0.85, 0.97)
)
library(dplyr)
# 定义一个函数来计算极差
calculate_range <- function(data, factor, response) {
# 计算每个因子水平下的响应变量平均值
means <- data %>%
group_by(!!sym(factor)) %>%
summarize(mean_response = mean(!!sym(response)))
# 计算极差
range_value <- max(means$mean_response) - min(means$mean_response)
return(range_value)
}
# 列出所有因子（包括交互效应）
factors <- c("A", "B", "AXB", "C", "AXC", "D")
response <- "ExperimentData"
# 计算所有因子的极差
range_results <- sapply(factors, function(factor) calculate_range(data, factor, response))
# 将结果转换为数据框，便于查看和排序
range_df <- data.frame(
Factor = names(range_results),
Range = range_results
)
range_df
print("各因子的极差结果：")
print(range_df)
